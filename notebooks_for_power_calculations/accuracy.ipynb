{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.contingency_tables import mcnemar                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(prob_table, dataset_size, alpha=0.05, r=5000):\n",
    "\n",
    "    if prob_table[0, 1] == prob_table[1, 0]:\n",
    "        raise RuntimeError(\"Power is undefined when the true effect is zero.\")\n",
    "\n",
    "    pvals = []\n",
    "    diffs = []\n",
    "    for i in range(r):  # number of simulations\n",
    "        sample = np.random.multinomial(n=dataset_size, pvals=prob_table.reshape((4,))).reshape((2,2))\n",
    "        acc_diff = (sample[0,1] - sample[1, 0]) / dataset_size\n",
    "        test_results = mcnemar(sample)\n",
    "        pvals.append(test_results.pvalue)\n",
    "        diffs.append(acc_diff)\n",
    "\n",
    "    true_diff = prob_table[0, 1] - prob_table[1, 0]\n",
    "    true_sign = np.sign(true_diff) \n",
    "    sig_diffs = [d for i, d in enumerate(diffs) if pvals[i] <= alpha]\n",
    "    power = len([d for i, d in enumerate(diffs) if pvals[i] <= alpha and np.sign(d) == true_sign]) / r\n",
    "    mean_effect = np.mean(diffs)\n",
    "    type_m = np.mean(np.abs(sig_diffs) / np.abs(true_diff))\n",
    "    type_s = np.mean(np.sign(sig_diffs) != true_sign)\n",
    "    return power, mean_effect, type_m, type_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability table for maximal agreement:\n",
      "[[0.28 0.  ]\n",
      " [0.02 0.7 ]]\n",
      "acc1 = 0.72\n",
      "acc2 = 0.7\n",
      "\n",
      "Upper bounds:\n",
      "Approx power = 1.000\n",
      "Approx Type-M error = 0.995\n",
      "Approx Type-S error = 0.000\n",
      "\n",
      "Probability table for minimal agreement:\n",
      "[[0.   0.3 ]\n",
      " [0.28 0.42]]\n",
      "acc1 = 0.7\n",
      "acc2 = 0.72\n",
      "\n",
      "\n",
      "Lower bounds:\n",
      "Approx power = 0.119\n",
      "Approx Type-M error = 3.004\n",
      "Approx Type-S error = 0.022\n"
     ]
    }
   ],
   "source": [
    "# If we ONLY know the difference in accuracy, one option is to compute bounds, assuming the best and worst case scneario\n",
    "\n",
    "baseline_acc = 0.7\n",
    "delta_acc = 0.02\n",
    "dataset_size = 1000\n",
    "r = 10000\n",
    "alpha = 0.05\n",
    "\n",
    "#### Case 1: maximal agreement on instances\n",
    "acc1 = baseline_acc\n",
    "acc2 = baseline_acc + delta_acc\n",
    "p_both_correct = min(acc1, acc2)\n",
    "p_diff = abs(acc1-acc2)\n",
    "p_both_incorrect = 1.0 - max(acc1, acc2)\n",
    "# create probability table [[both correct, only M1 correct], [only M2 correct, both incorrect]]\n",
    "if acc2 > acc1:\n",
    "    prob_table = np.array([[p_both_incorrect, 0], [p_diff, p_both_correct]]) \n",
    "else:\n",
    "    prob_table = np.array([[p_both_incorrect, p_diff], [0, p_both_correct]]) \n",
    "print(\"Probability table for maximal agreement:\")\n",
    "print(prob_table)\n",
    "print(\"acc1 =\", prob_table[1, :].sum())\n",
    "print(\"acc2 =\", prob_table[:, 1].sum())\n",
    "\n",
    "power, mean_effect, type_m, type_s = compute_power(prob_table, dataset_size, alpha=alpha, r=r)\n",
    "\n",
    "print(\"\\nUpper bounds:\")\n",
    "print(\"Approx power = {:.3f}\".format(power))\n",
    "print(\"Approx Type-M error = {:.3f}\".format(type_m))\n",
    "print(\"Approx Type-S error = {:.3f}\".format(type_s))\n",
    "\n",
    "#### Case 2: maximal disagreement on instances (assume acc > 0.5)\n",
    "\n",
    "error_rate_1 = 1.0 - acc1\n",
    "error_rate_2 = 1.0 - acc2\n",
    "p_both_correct = 1.0 - error_rate_1 - error_rate_2\n",
    "# create probability table [[cc, ci], [ic, ii]]\n",
    "prob_table = np.array([[0, error_rate_1], [error_rate_2, p_both_correct]])\n",
    "print(\"\\nProbability table for minimal agreement:\")\n",
    "print(prob_table)\n",
    "print(\"acc1 =\", prob_table[1, :].sum())\n",
    "print(\"acc2 =\", prob_table[:, 1].sum())\n",
    "print()\n",
    "\n",
    "power, mean_effect, type_m, type_s = compute_power(prob_table, dataset_size, alpha=alpha, r=r)\n",
    "\n",
    "print(\"\\nLower bounds:\")\n",
    "print(\"Approx power = {:.3f}\".format(power))\n",
    "print(\"Approx Type-M error = {:.3f}\".format(type_m))\n",
    "print(\"Approx Type-S error = {:.3f}\".format(type_s))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability table:\n",
      "[[0.1775 0.0225]\n",
      " [0.0025 0.7975]]\n",
      "acc1 = 0.800\n",
      "acc2 = 0.820\n",
      "\n",
      "Approx power = 0.800\n",
      "Approx Type-M error = 1.118\n",
      "Approx Type-S error = 0.000\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can an use estimated values for agreement\n",
    "\n",
    "agreement_rate = 0.975\n",
    "baseline_acc = 0.8\n",
    "delta_acc = 0.02\n",
    "dataset_size = 500\n",
    "r = 10000\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "acc1 = baseline_acc\n",
    "acc2 = baseline_acc + delta_acc\n",
    "\n",
    "disagreement_rate = 1 - agreement_rate\n",
    "if delta_acc > 0:\n",
    "    p_only_1_correct = (disagreement_rate - delta_acc) / 2 \n",
    "    p_only_2_correct = (disagreement_rate - delta_acc) / 2 + delta_acc\n",
    "else:\n",
    "    p_only_1_correct = (disagreement_rate + delta_acc) / 2 - delta_acc\n",
    "    p_only_2_correct = (disagreement_rate + delta_acc) / 2 \n",
    "\n",
    "p_both_correct = acc1 - p_only_1_correct\n",
    "assert np.abs(p_both_correct - (acc2 - p_only_2_correct)) < 1e-4\n",
    "p_both_incorrect = 1. - p_both_correct - p_only_1_correct - p_only_2_correct\n",
    "\n",
    "for p in [p_both_correct, p_only_1_correct, p_only_2_correct, p_both_incorrect]:\n",
    "    assert p >= 0\n",
    "\n",
    "prob_table = np.array([[p_both_incorrect, p_only_2_correct], [p_only_1_correct, p_both_correct]]) \n",
    "print(\"Probability table:\")\n",
    "print(prob_table)\n",
    "print(\"acc1 = {:.3f}\".format(prob_table[1, :].sum()))\n",
    "print(\"acc2 = {:.3f}\".format(prob_table[:, 1].sum()))\n",
    "\n",
    "power, mean_effect, type_m, type_s = compute_power(prob_table, dataset_size, alpha=alpha, r=r)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Approx power = {:.3f}\".format(power))\n",
    "print(\"Approx Type-M error = {:.3f}\".format(type_m))\n",
    "print(\"Approx Type-S error = {:.3f}\".format(type_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
